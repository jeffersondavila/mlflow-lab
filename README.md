# ğŸš€ spark-mlflow

Entorno Docker personalizado que combina:

- ğŸ“˜ **JupyterLab**: Entorno interactivo para notebooks con PySpark.
- ğŸ”¥ **Apache Spark**: Motor de procesamiento distribuido.
- ğŸ§ª **MLflow**: Seguimiento y visualizaciÃ³n de experimentos de Machine Learning.

Ideal para proyectos locales de ciencia de datos, pruebas de modelos y desarrollo reproducible.

---

## âœ… Â¿QuÃ© incluye este entorno?

- Una imagen Docker basada en `jupyter/all-spark-notebook`.
- MLflow instalado y ejecutÃ¡ndose automÃ¡ticamente.
- Un Ãºnico contenedor que expone JupyterLab, MLflow UI y Spark UI.
- Carpeta `./notebooks` montada como volumen persistente para guardar tu trabajo.

---

## ğŸ“¦ Requisitos

Antes de usar este entorno, asegÃºrate de tener instalado:

- Docker: https://docs.docker.com/get-docker/
- Docker Compose: https://docs.docker.com/compose/install/

---

## â–¶ï¸ CÃ³mo usar

1. Clona este repositorio:
`git clone https://github.com/jeffersondavila/spark-mlflow.git`
`cd spark-mlflow`

2. Ejecuta el entorno con Docker Compose:
`docker-compose up --build`

3. Accede a los servicios:
- JupyterLab: http://localhost:8888
- MLflow UI: http://localhost:5000
- Spark UI: http://localhost:4040

4. Para detener el entorno:
`docker-compose down`
